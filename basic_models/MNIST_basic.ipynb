{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-29 03:38:48.988234: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 03:38:48.992981: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-29 03:38:49.005260: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730162329.025840  201507 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730162329.031136  201507 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-29 03:38:49.052573: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Reshape,Conv2D, MaxPool2D,Flatten,Dense, Dropout, Rescaling\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "from tensorflow.keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "\n",
    "train_df = pd.read_csv('raw_data/sign_mnist_train.csv')\n",
    "test_df = pd.read_csv('raw_data/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "17    1294\n",
       "16    1279\n",
       "11    1241\n",
       "22    1225\n",
       "5     1204\n",
       "18    1199\n",
       "14    1196\n",
       "3     1196\n",
       "19    1186\n",
       "23    1164\n",
       "8     1162\n",
       "20    1161\n",
       "13    1151\n",
       "2     1144\n",
       "0     1126\n",
       "24    1118\n",
       "10    1114\n",
       "6     1090\n",
       "15    1088\n",
       "21    1082\n",
       "12    1055\n",
       "7     1013\n",
       "1     1010\n",
       "4      957\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X,y - test and train sets\n",
    "X_train=train_df.drop(columns = 'label')\n",
    "X_test = test_df.drop(columns = 'label')\n",
    "\n",
    "y_train = train_df.label\n",
    "y_test = test_df.label\n",
    "\n",
    "#X to numpy and apply reshape from 784 columns to (28,28,1)\n",
    "numpy_X_train = X_train.to_numpy()\n",
    "numpy_X_test = X_test.to_numpy()\n",
    "\n",
    "X_train_shaped = np.apply_along_axis(lambda x:np.reshape(x,(28,28,1)),1,numpy_X_train)\n",
    "X_test_shaped = np.apply_along_axis(lambda x:np.reshape(x,(28,28,1)),1,numpy_X_test)\n",
    "\n",
    "# encode y\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_test_cat = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 28, 28, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation (borrowed) NOT USED ATM\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(X_train_shaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diana/.pyenv/versions/3.10.6/envs/sign_language_interpreter/lib/python3.10/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#model initiation\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Rescaling(scale = 1./255.,input_shape = (28,28,1)))\n",
    "\n",
    "model.add(Conv2D(16,(4,4),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(64,(2,2),padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(50,activation ='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 47ms/step - accuracy: 0.0427 - loss: 3.2132 - val_accuracy: 0.1747 - val_loss: 3.0434\n",
      "Epoch 2/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.1558 - loss: 2.7928 - val_accuracy: 0.6392 - val_loss: 1.5821\n",
      "Epoch 3/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.3955 - loss: 1.8685 - val_accuracy: 0.7571 - val_loss: 0.9844\n",
      "Epoch 4/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.5145 - loss: 1.4359 - val_accuracy: 0.8512 - val_loss: 0.6371\n",
      "Epoch 5/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.5998 - loss: 1.1652 - val_accuracy: 0.8844 - val_loss: 0.5152\n",
      "Epoch 6/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.6502 - loss: 1.0045 - val_accuracy: 0.8995 - val_loss: 0.4174\n",
      "Epoch 7/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.6867 - loss: 0.8930 - val_accuracy: 0.9245 - val_loss: 0.3700\n",
      "Epoch 8/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.7059 - loss: 0.8489 - val_accuracy: 0.9429 - val_loss: 0.3009\n",
      "Epoch 9/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.7407 - loss: 0.7554 - val_accuracy: 0.9523 - val_loss: 0.2582\n",
      "Epoch 10/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 58ms/step - accuracy: 0.7530 - loss: 0.7040 - val_accuracy: 0.9642 - val_loss: 0.2302\n",
      "Epoch 11/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.7678 - loss: 0.6717 - val_accuracy: 0.9712 - val_loss: 0.1974\n",
      "Epoch 12/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.7813 - loss: 0.6237 - val_accuracy: 0.9723 - val_loss: 0.1817\n",
      "Epoch 13/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.7867 - loss: 0.6142 - val_accuracy: 0.9738 - val_loss: 0.1622\n",
      "Epoch 14/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8050 - loss: 0.5519 - val_accuracy: 0.9811 - val_loss: 0.1339\n",
      "Epoch 15/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8106 - loss: 0.5469 - val_accuracy: 0.9795 - val_loss: 0.1281\n",
      "Epoch 16/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.8192 - loss: 0.5246 - val_accuracy: 0.9809 - val_loss: 0.1156\n",
      "Epoch 17/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.8249 - loss: 0.4984 - val_accuracy: 0.9839 - val_loss: 0.1042\n",
      "Epoch 18/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8323 - loss: 0.4809 - val_accuracy: 0.9826 - val_loss: 0.0958\n",
      "Epoch 19/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8370 - loss: 0.4567 - val_accuracy: 0.9857 - val_loss: 0.0850\n",
      "Epoch 20/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8430 - loss: 0.4505 - val_accuracy: 0.9909 - val_loss: 0.0789\n",
      "Epoch 21/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8432 - loss: 0.4468 - val_accuracy: 0.9899 - val_loss: 0.0673\n",
      "Epoch 22/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8549 - loss: 0.4265 - val_accuracy: 0.9934 - val_loss: 0.0630\n",
      "Epoch 23/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.8620 - loss: 0.3881 - val_accuracy: 0.9933 - val_loss: 0.0608\n",
      "Epoch 24/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.8612 - loss: 0.3848 - val_accuracy: 0.9951 - val_loss: 0.0529\n",
      "Epoch 25/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8702 - loss: 0.3736 - val_accuracy: 0.9956 - val_loss: 0.0521\n",
      "Epoch 26/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - accuracy: 0.8720 - loss: 0.3675 - val_accuracy: 0.9966 - val_loss: 0.0429\n",
      "Epoch 27/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - accuracy: 0.8700 - loss: 0.3635 - val_accuracy: 0.9953 - val_loss: 0.0419\n",
      "Epoch 28/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - accuracy: 0.8717 - loss: 0.3673 - val_accuracy: 0.9985 - val_loss: 0.0383\n",
      "Epoch 29/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 65ms/step - accuracy: 0.8777 - loss: 0.3393 - val_accuracy: 0.9992 - val_loss: 0.0325\n",
      "Epoch 30/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8847 - loss: 0.3273 - val_accuracy: 0.9958 - val_loss: 0.0345\n",
      "Epoch 31/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.8862 - loss: 0.3164 - val_accuracy: 0.9989 - val_loss: 0.0280\n",
      "Epoch 32/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 56ms/step - accuracy: 0.8882 - loss: 0.3217 - val_accuracy: 0.9987 - val_loss: 0.0265\n",
      "Epoch 33/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8968 - loss: 0.3050 - val_accuracy: 0.9975 - val_loss: 0.0257\n",
      "Epoch 34/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8946 - loss: 0.3029 - val_accuracy: 0.9993 - val_loss: 0.0246\n",
      "Epoch 35/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.8989 - loss: 0.2925 - val_accuracy: 0.9962 - val_loss: 0.0287\n",
      "Epoch 36/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.8970 - loss: 0.2935 - val_accuracy: 0.9998 - val_loss: 0.0185\n",
      "Epoch 37/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9049 - loss: 0.2731 - val_accuracy: 0.9999 - val_loss: 0.0189\n",
      "Epoch 38/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.8982 - loss: 0.2982 - val_accuracy: 0.9993 - val_loss: 0.0211\n",
      "Epoch 39/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9048 - loss: 0.2703 - val_accuracy: 0.9984 - val_loss: 0.0171\n",
      "Epoch 40/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.9030 - loss: 0.2765 - val_accuracy: 0.9995 - val_loss: 0.0177\n",
      "Epoch 41/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.9043 - loss: 0.2683 - val_accuracy: 0.9998 - val_loss: 0.0144\n",
      "Epoch 42/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9085 - loss: 0.2669 - val_accuracy: 0.9993 - val_loss: 0.0177\n",
      "Epoch 43/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9086 - loss: 0.2721 - val_accuracy: 0.9999 - val_loss: 0.0129\n",
      "Epoch 44/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.9111 - loss: 0.2558 - val_accuracy: 0.9998 - val_loss: 0.0115\n",
      "Epoch 45/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.9079 - loss: 0.2612 - val_accuracy: 0.9998 - val_loss: 0.0124\n",
      "Epoch 46/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 55ms/step - accuracy: 0.9086 - loss: 0.2563 - val_accuracy: 0.9990 - val_loss: 0.0119\n",
      "Epoch 47/100\n",
      "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.9140 - loss: 0.2490 - val_accuracy: 0.9995 - val_loss: 0.0125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fd0c85c6410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting using augmented dataset\n",
    "\n",
    "es = EarlyStopping(patience = 3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model.fit(X_train_shaped,y_train_cat,batch_size =128,validation_split=0.3,epochs = 100, callbacks=es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving model (no changes at this point)\n",
    "\n",
    "save_model(model,'MNIST_basic_one.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=basic_models/MNIST_basic_one.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#loading for evaluation&prediction\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbasic_models/MNIST_basic_one.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/sign_language_interpreter/lib/python3.10/site-packages/keras/src/saving/saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: filepath=basic_models/MNIST_basic_one.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "#loading for evaluation&prediction\n",
    "\n",
    "loaded_model = load_model('MNIST_basic_one.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9619 - loss: 0.1049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09751017391681671, 0.9651421904563904]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(X_test_shaped,y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the image from net for prediction\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "img = Image.open('w.jpg')\n",
    "img = img.resize((28,28))\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using one of the images from test set to see that it works (as opposed to one from net)\n",
    "\n",
    "check = X_test_shaped[7].reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n"
     ]
    }
   ],
   "source": [
    "#prediction using image from net\n",
    "res = loaded_model.predict(img)[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#note that there are no images for j in dataset but it is still included there\n",
    "\n",
    "alphabet=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y']\n",
    "len(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight\n",
       "h    0.54\n",
       "g    0.27\n",
       "l    0.14\n",
       "p    0.02\n",
       "t    0.01\n",
       "r    0.01\n",
       "x    0.01\n",
       "b    0.00\n",
       "a    0.00\n",
       "i    0.00\n",
       "f    0.00\n",
       "d    0.00\n",
       "e    0.00\n",
       "c    0.00\n",
       "m    0.00\n",
       "k    0.00\n",
       "j    0.00\n",
       "q    0.00\n",
       "o    0.00\n",
       "n    0.00\n",
       "s    0.00\n",
       "u    0.00\n",
       "v    0.00\n",
       "w    0.00\n",
       "y    0.00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the prediction\n",
    "\n",
    "prediction = pd.DataFrame(res,index=alphabet,columns =['weight'])\n",
    "prediction.sort_values(by = 'weight',ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just to see the images in the dataset as they are\n",
    "\n",
    "check = np.reshape(X_train.iloc[7],(28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2fbc3caf80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_language_interpreter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
