{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bounding_rect(image, landmarks):\n",
    "\n",
    "    padding = 20\n",
    "\n",
    "    image_width, image_height = image.shape[1], image.shape[0]\n",
    "\n",
    "    landmark_array = np.empty((0, 2), int)\n",
    "\n",
    "    for _, landmark in enumerate(landmarks.landmark):\n",
    "        landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
    "        landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
    "\n",
    "        landmark_point = [np.array((landmark_x, landmark_y))]\n",
    "\n",
    "        landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(landmark_array)\n",
    "\n",
    "    return [x-padding, y-padding, x + w + (padding), y + h + (padding)]\n",
    "\n",
    "def draw_bounding_rect(use_brect, image, brect):\n",
    "    if use_brect:\n",
    "        # Outer rectangle\n",
    "        cv2.rectangle(image, (brect[0], brect[1]), (brect[2], brect[3]),\n",
    "                     (0, 0, 0), 1)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def extract_hand(path):\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=True,\n",
    "                       max_num_hands=2,\n",
    "                       min_detection_confidence=0.5,\n",
    "                       min_tracking_confidence=0.5)\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    debug_image = copy.deepcopy(image)\n",
    "\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "    mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            results.multi_hand_landmarks[0],\n",
    "            mp_hands.HAND_CONNECTIONS\n",
    "        )\n",
    "\n",
    "    if results.multi_hand_landmarks is not None:\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for hand_landmarks, handedness in zip(results.multi_hand_landmarks,\n",
    "                                                    results.multi_handedness):\n",
    "            # Bounding box calculation\n",
    "            brect = calc_bounding_rect(debug_image, hand_landmarks)\n",
    "            x_min, y_min, x_max, y_max = brect\n",
    "\n",
    "            # Crop the hand region from the image based on bounding rectangle\n",
    "            #+1 pixel to remove the outer border of the picture\n",
    "            hand_region = image[y_min+1:y_max, x_min+1:x_max]\n",
    "\n",
    "            # Drawing part\n",
    "            image = draw_bounding_rect(True, image, brect)\n",
    "\n",
    "\n",
    "\n",
    "            return image, hand_region\n",
    "\n",
    "\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1731366299.919768   69681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1731366299.946265   69681 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "/home/diana/.pyenv/versions/3.10.6/envs/sign_language_interpreter/lib/python3.10/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "image,hand = extract_hand(\"API/w.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]\\n\\n [[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]\\n\\n [[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]\\n\\n ...\\n\\n [[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]\\n\\n [[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]\\n\\n [[255 255 255]\\n  [255 255 255]\\n  [255 255 255]\\n  ...\\n  [255 255 255]\\n  [255 255 255]\\n  [255 255 255]]]'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'imread'\n> Overload resolution failed:\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n>  - Expected 'filename' to be a str or path-like object\n"
     ]
    }
   ],
   "source": [
    "cv2.imread(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_language_interpreter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
